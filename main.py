
# Drone X project Main Program File 2022
import math

# # Double '# #' are used for code comments and explanations
# Single '#' are used for commented code

# # OpenCV Real TIme Computer Vision Library/API
import cv2
# # MediaPipe Machine Learning for Computer Vision and Pose Estimation
import mediapipe as mp
import time
# # DJITello dedicated API for drone connection and control Licensed by MIT
from djitellopy import tello

CAMFOCALPOINT = 288
SHOULDERINCHES = 15


# # Approximation Functions for Pose Distinctions
def precise3(first, second, third):
    if second - 5 <= first <= second + 5 and third - 5 <= first <= third + 5:
        return True


def approximate3(first, second, third):
    if second - 10 <= first <= second + 10 and third - 10 <= first <= third + 10:
        return True


def approximate2(first, second):
    if second - 10 <= first <= second + 10:
        return True


def vague2(first, second):
    if second - 20 <= first <= second + 20:
        return True


# # MediaPipe drawing utilities to overlay graphics specific body landmarks over
# # visual inputs to make an outline of the person or persons in view.
# # mpPose is specific to body landmarks ranging 32 points from head to toe
mpDraw = mp.solutions.drawing_utils
mpPose = mp.solutions.pose
pose = mpPose.Pose()


# # mpHand is specific to the hands crating 20 points per hand for more detailed use of finger gestures
# mpHands = mp.solutions.hands
# hands = mpHands.Hands()


# # Video capture from laptop video feed
# cap = cv2.VideoCapture(0)

# # Time variables used for FPS and travel calculations
pTime = 0
count = 0

# # Creation of Drone object for interaction and connection to Drone X
drone = tello.Tello()
drone.connect()

# # Check Successful connection with battery check and print
print(drone.get_battery())

# # Establish connection to Drone X video feed
drone.streamon()

# drone.set_video_resolution(drone.RESOLUTION_720P)

# # Conditional Statements for current state of Drone X operation
cont = True
droneInAir = False
followMode = False


# # Continuous loop for user interaction with Drone X
while cont:
    # # Successful connection and reading of Laptop video feed
    # success, img = cap.read()

    # # stores frames from video feed into img variable
    img = drone.get_frame_read().frame
    # img = drone.get_video_capture()
    # # resize stored img to a smaller size for processing and display
    img = cv2.resize(img, (360, 240))

    # # Display of Drone X video feed
    cv2.imshow("Image ", img)
    cv2.waitKey(1)

    # # Conversion of photo to RGB format and then passing it to the MediaPipe API
    # # to process the image and find body pose landmarks
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # # Full body specific pose estimation processing
    results = pose.process(imgRGB)
    # # Hand specific pose estimation processing
    # resultsh = hands.process(imgRGB)

    # # Checks if results finds Full body Pose Landmarks and then does the following
    if results.pose_landmarks:
        # # draws Full body pose landmarks and connecting lines between landmark points
        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)

        # # FPS calculation and display on image
        cTime = time.time()
        fps = 1 / (cTime - pTime)
        pTime = cTime
        cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)

        # # Display of MediaPipe Processed Image
        cv2.imshow("Image", img)
        cv2.waitKey(1)

        # # Prints Full Body landmark information in X,Y,Z percentage format generated by MediaPipe
        # for pose in results.pose_landmarks:
            # print(results.pose_landmarks)

        # # Creation of empty Landmark List
        lmList = []

        # # for loop to store each landmark's stored values into the Landmark list and convert the
        # # X,Y,Z percentage data into coordinate data with origin point in the top
        # # left corner of the displayed and processed image
        for ID, lm in enumerate(results.pose_landmarks.landmark):
            h, w, c = img.shape
            cx, cy, cz= int(lm.x*w), int(lm.y*h), int(lm.z)
            # print(id, " x:", cx, " y:", cy)
            lmList.append([ID, cx, cy, cz])

        # #List of References and Variables in Lay-mans Relational naming
        # #separated by X and Y coordinate value in Landmark List
        # #that correlate to the Landmark List against
        # #MediaPipe's Landmark Map
        
        landmarkDict.update({"noseX": lmLikst[0][1]})
        # #noseX = lmList[0][1]
        landmarkDict.update({"noseY": lmLikst[0][2]})
        # #noseY = lmList[0][2]

        # 2 is left eye
        # 5 is right eye

        # 7 is left ear
        # 8 is right ear
        landmarkDict.update({"leftShoulderX": lmLikst[11][1]})
        # #leftShoulderX = lmList[11][1]
        landmarkDict.update({"leftShoulderY": lmLikst[11][2]})
        # #leftShoulderY = lmList[11][2]

        landmarkDict.update({"rightShoulderX": lmLikst[12][1]})
        # #rightShoulderX = lmList[12][1]
        landmarkDict.update({"rightShoulderY": lmLikst[12][2]})
        # #rightShoulderY = lmList[12][2]

        landmarkDict.update({"leftElbowX": lmLikst[13][1]})
        # #leftElbowX = lmList[13][1]
        landmarkDict.update({"leftElbowY": lmLikst[13][2]})
        # #leftElbowY = lmList[13][2]

        landmarkDict.update({"rightElbowX": lmLikst[14][1]})
        # #rightElbowX = lmList[14][1]
        landmarkDict.update({"rightElbowY": lmLikst[14][2]})
        # #rightElbowY = lmList[14][2]

        landmarkDict.update({"leftWristX": lmLikst[15][1]})
        # #leftWristX = lmList[15][1]
        landmarkDict.update({"leftWristY": lmLikst[15][2]})
        # #leftWristY = lmList[15][2]

        rightWristX = lmList[16][1]
        rightWristY = lmList[16][2]

        leftHipX = lmList[23][1]
        leftHipY = lmList[23][2]

        rightHipX = lmList[24][1]
        rightHipY = lmList[24][2]

        # # CURRENT list of Drone X Command Structure statements for gesture recognition
        # # and responsive action from Drone X
        if not droneInAir:
            # # DRONE X TAKEOFF
            # if leftWristY < noseY and rightWristY < noseY:
            if leftWristY < noseY or rightWristY < noseY:
                drone.takeoff()
                droneInAir = True
                drone.send_rc_control(0, 0, 0, 0)   # sent to ensure it does not keep spinning from the last session
                print("DRONE X TAKES OFF")

        elif not followMode and droneInAir:
            # print("perceived pixels: ", leftShoulderX - rightShoulderX)
            # # DRONE X STOPS MOVING
            if droneInAir and leftWristX < rightWristX and leftWristY > leftShoulderY:
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X LANDS")
                drone.land()
                cont = False

            # # DRONE X MOVES TO DRONE RIGHT, TO PERSON LEFT
            elif droneInAir and approximate3(leftWristY, leftElbowY, leftShoulderY) and \
                    approximate3(rightWristX, rightElbowX, rightShoulderX):
                drone.move_right(50)
                print("DRONE X MOVES TO DRONE RIGHT, TO PERSON LEFT")

            # # DRONE X MOVES TO DRONE LEFT, TO PERSON RIGHT
            elif droneInAir and approximate3(rightWristY, rightElbowY, rightShoulderY) and \
                    approximate3(leftWristX, leftElbowX, leftShoulderX):
                drone.move_left(50)
                print("DRONE X MOVES TO DRONE LEFT, TO PERSON RIGHT")

            # # DRONE X GO UP
            elif droneInAir and leftWristY < noseY - 10 and rightWristY < noseY - 10:
                drone.move_up(30)
                print("DRONE X MOVES UP")

            # #DRONE X MOVES FORWARDS, TOWARDS PERSON
            elif droneInAir and leftWristX < leftShoulderX and leftShoulderY < leftWristY < leftElbowY \
                    and rightWristX > rightShoulderX and rightShoulderY < rightWristY < rightElbowY:
                drone.move_forward(50)
                print("DRONE X MOVES FORWARD")

            # # DRONE X MOVES BACKWARDS, AWAY FROM PERSON
            elif droneInAir and approximate3(rightWristX, rightShoulderX, rightElbowX) \
                    and approximate3(rightWristY, rightShoulderY, rightElbowY):
                drone.move_back(50)
                print("DRONE X MOVES BACKWARDS")

            # # DRONE X STARTS FOLLOW MODE
            elif droneInAir and approximate2(leftWristY, rightWristY) and vague2(leftWristX, rightWristX) and \
                    rightWristY < rightShoulderY:
                startingPixelsFront = leftShoulderX - rightShoulderX
                startingPixelsBack = rightShoulderX - leftShoulderX
                print("DRONE X STARTS FOLLOWING")
                print("startingPixelsFront =", startingPixelsFront)
                startingDistanceToUser = (SHOULDERINCHES * CAMFOCALPOINT)/startingPixelsFront  # in inches
                followMode = True
                time.sleep(3)
            # print("LeftWrist Y: ", leftWristY, " RightWrist Y: ", rightWristY)
            # print("LeftWrist X: ", leftWristX, " RightWrist X: ", rightWristX)

        # # DRONE X IN FOLLOW MODE
        elif followMode:
            currentPixelsFront = leftShoulderX - rightShoulderX  # distance in between shoulders
            currentPixelsBack = rightShoulderX - leftShoulderX
            if currentPixelsFront != 0:
                currentDistanceToUser = (SHOULDERINCHES * CAMFOCALPOINT)/currentPixelsFront  # in inches
            # print("distance =", currentDistanceToUser, "inches   drone height =", drone.get_height())

            # # GET MIDDLE OF IMAGE
            height, width = img.shape[0:2]
            mid = width/2
            midHeight = height/2

            # # DRONE X LANDS
            if droneInAir and leftWristX < rightWristX and leftWristY > leftShoulderY:
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X LANDS")
                drone.land()
                cont = False

#############################################################################################
            # # USER IS LEFT OF THE DRONE
            if (noseX > mid) and (noseX - mid) > 50:
                drone.send_rc_control(0, 0, 0, 30)
                print("DRONE X ROTATE CLOCKWISE")
                # noseDistance = noseX - mid
                # opposite = (noseX - mid)/currentPixelsFront * SHOULDERINCHES
                # print("noseX =", noseX, "distanceToUser =", currentDistanceToUser,
                #       "currentPixelsFront =", currentPixelsFront)
                # drone.rotate_clockwise(int(math.degrees(math.atan(opposite/currentDistanceToUser))))
                # print("DRONE X ROTATE CLOCKWISE BY ", int(math.degrees(math.atan(opposite/currentDistanceToUser))))

            # # USER IS RIGHT OF THE DRONE
            elif(mid > noseX) and (mid - noseX) > 50:
                drone.send_rc_control(0, 0, 0, -30)
                print("DRONE X ROTATE COUNTER CLOCKWISE")
            #     noseDistance = mid - noseX
            #     opposite = (mid - noseX)/currentPixelsFront * SHOULDERINCHES
            #     print("noseX =", noseX, "distanceToUser =", currentDistanceToUser,
            #           "currentPixelsFront =", currentPixelsFront)
            #     drone.rotate_counter_clockwise(int(math.degrees(math.atan(opposite/currentDistanceToUser))))
            #     print("DRONE X ROTATE COUNTER-CLOCKWISE BY ",
            #           int(math.degrees(math.atan(opposite/currentDistanceToUser))))
#############################################################################################
            # # USER IS TWO FOOT AWAY FROM THE STARTING POSITION
            elif currentDistanceToUser > (startingDistanceToUser + 24):
                print("noseX =", noseX, "distanceToUser =", currentDistanceToUser,
                      "currentPixelsFront =", currentPixelsFront, "startingDistanceToUser =", startingDistanceToUser)
                drone.send_rc_control(0, 50, 0, 0)
                print("DRONE X FOLLOW FORWARD")

            # # USER IS TWO FOOT CLOSER TO THE STARTING POSITION
            elif currentDistanceToUser < (startingDistanceToUser - 24):
                print("noseX =", noseX, "distanceToUser =", currentDistanceToUser,
                      "currentPixelsFront =", currentPixelsFront, "startingDistanceToUser =", startingDistanceToUser)
                drone.send_rc_control(0, -20, 0, 0)
                print("DRONE X FOLLOW backward")
#############################################################################################
            # # DRONE IS ABOVE USER SHOULDERS
            elif leftShoulderY > midHeight + 30:
                drone.send_rc_control(0, 0, -30, 0)
                print("DRONE X MOVES DOWN")

            # # DRONE IS BELOW USER SHOULDERS
            elif leftShoulderY < midHeight - 30:
                drone.send_rc_control(0, 0, 30, 0)
                print("DRONE X MOVES UP")
#############################################################################################
            # # DRONE SHOULD NOT MOVE
            elif (mid - 30) < noseX < (mid + 30):
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE STAYS PUT CLOCKWISE")
            elif (startingDistanceToUser + 6) > currentDistanceToUser > (startingDistanceToUser - 6):
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X FOLLOW STOP MOVING")
            elif midHeight - 30 > leftShoulderY > midHeight + 15:
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X STOP MOVING HEIGHT")

            # # EXIT FOLLOW MODE
            if droneInAir and approximate2(leftWristY, rightWristY) and vague2(leftWristX, rightWristX) and \
                    rightWristY < rightShoulderY:
                followMode = False
                drone.send_rc_control(0, 0, 0, 0)
                print("DRONE X END FOLLOW MODE")
                time.sleep(3)

exit()


# MIT License
#
# Copyright (c) 2018 DAMIÀ FUENTES ESCOTÉ
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.