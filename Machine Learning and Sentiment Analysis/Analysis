import json
import pandas as pd # type: ignore
import re
import nltk
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score, roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.preprocessing import LabelEncoder
from imblearn.under_sampling import RandomUnderSampler
from imblearn.ensemble import BalancedRandomForestClassifier
from sklearn.model_selection import GridSearchCV

data = []
with open("Appliancesdata.json", "r") as file:
    for line in file:
        line = line.strip()  # Remove any surrounding whitespace
        if not line:  # Skip empty lines
            continue
        try:
            data.append(json.loads(line))  # Parse the line as JSON
        except json.JSONDecodeError as e:
            print(f"Skipping invalid line: {line}")
            print(f"Error: {e}")

Df = pd.DataFrame(data)

Df["cleaned_review"] = Df["reviewText"].apply(PreprocessText)
Vectorizer = CountVectorizer()
X = Vectorizer.fit_transform(Df["cleaned_review"])
XTrain, XTest, YTrain, YTest = train_test_split(X, Df["Sentiment"], test_size = 0.2, random_state = 42)
RFModel = RandomForestClassifier(n_estimators = 10, max_depth = 20, random_state = 20, class_weight = "balanced_subsample")

Label = LabelEncoder()
YTrainEncoded = Label.fit_transform(YTrain)
YTestEncoded = Label.transform(YTest)

RFModel.fit(XTrain, YTrainEncoded)
Predictions = RFModel.predict(XTest)

RS = RandomUnderSampler(random_state = 22)
XTrainRes, YTrainRes = RS.fit_resample(X= XTrain, y=YTrainEncoded)
Forest = RandomForestClassifier(n_estimators = 10, max_depth = 20, random_state = 20, class_weight = "balanced_subsample")
Forest.fit(XTrainRes, YTrainRes)
Predictions = Forest.predict(XTest)

SM = SMOTE(random_state = 2)
XTrainRes, YTrainRes = SM.fit_resample(X = XTrain, y = YTrainEncoded)
Forest = RandomForestClassifier(n_estimators = 10, max_depth = 20, random_state = 20, class_weight = "balanced")
Forest.fit(XTrainRes, YTrainRes)
Predictions = Forest.predict(XTest)

pipeline = ImbPipeline([
    ('smote', SMOTE(random_state=2)),
    ('rf', RandomForestClassifier(random_state=20))
])

param_grid = {
    'rf__n_estimators': [50, 100],
    'rf__max_depth': [20, 50, None],
    'rf__class_weight': [{0: 7, 1: 1, 2: 1}, "balanced"]
}

grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_weighted', cv=5)
grid_search.fit(XTrain, YTrainEncoded)
TestPredictions = grid_search.predict(XTest)

Df['review_Text'] = Df['cleaned_review'].apply(len)
UniqueValues = np.sort(Df['review_Text'].unique())
TotalGini = GetTotalGini(UniqueValues, 'review_Text', Df)
ReportSplits(UniqueValues, TotalGini)
Threshold = GetThreshold(UniqueValues, TotalGini)

print("Now we will test the model on the split data.")
SM = SMOTE(random_state=42)
XTrainTes2, YTrainRes2 = SM.fit_resample(X = NewXTrain, y = YTrainEncoded2) 
FinalModel = RandomForestClassifier(n_estimators = 10, max_depth = 20, random_state = 20, class_weight = "balanced_subsample")
FinalModel.fit(XTrainTes2, YTrainRes2)
FinalPredictions = FinalModel.predict(NewXTest)

ParamGrid = {
    'n_estimators': [10, 50, 100,],
    'max_depth': [10, 20, 50],
    'class_weight': [{0: 5, 1: 1, 2: 1}, "balanced", "balanced_subsample"]
}

GridSearch = GridSearchCV(FinalModel, ParamGrid, cv=3, scoring="f1_weighted")
GridSearch.fit(XTrainTes2, YTrainRes2)
# GridSearch.fit(NewXTrain, YTrainEncoded2)
BestMmodel = GridSearch.best_estimator_

BetterFinalModel = RandomForestClassifier(
    n_estimators=100,
    max_depth=50,
    class_weight='balanced'
)

BetterFinalModel.fit(XTrainTes2, YTrainRes2)
FinalPredictions = BetterFinalModel.predict(NewXTest).ravel()

ParamGrid = {
    'n_estimators': [10, 50, 100,],
    'max_depth': [10, 20, 50],
    'class_weight': [{0: 5, 1: 1, 2: 1}, "balanced", "balanced_subsample"]
}

GridSearch = GridSearchCV(RFModel, ParamGrid, cv=3, scoring="f1_weighted")
GridSearch.fit(XTrain, YTrainEncoded)
BestMmodel = GridSearch.best_estimator_
BetterRFModel = RandomForestClassifier(
    n_estimators = 5,
    max_depth = 50,
    class_weight={0: 5, 1: 1, 2: 1},
    random_state=20
)

# BetterRFModel.fit(XTrainRes, YTrainRes)
BetterRFModel.fit(XTrain, YTrainEncoded)
NewPredictions = BetterRFModel.predict(XTest).ravel()
